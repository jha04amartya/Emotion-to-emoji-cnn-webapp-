{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NIKKS1234/EMOTION_TO_EMOJI/blob/main/MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53a8b15",
      "metadata": {
        "id": "f53a8b15"
      },
      "outputs": [],
      "source": [
        "#importing all the libraries required for the program to work\n",
        "import numpy as np\n",
        "import random \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob as gb\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,ZeroPadding2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
        "from keras.models import Model,Sequential\n",
        "from keras.optimizers import Adam,SGD,RMSprop\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1f09de",
      "metadata": {
        "id": "7f1f09de"
      },
      "outputs": [],
      "source": [
        "picture_size = 48\n",
        "folder_path = \"C:/Users/AMARTY JHA/3D Objects/data\"\n",
        "output = r\"C:\\Users\\AMARTY JHA\\3D Objects\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc41d60",
      "metadata": {
        "id": "9dc41d60"
      },
      "outputs": [],
      "source": [
        "#showing sample dataset\n",
        "expression = 'happy'\n",
        "\n",
        "plt.figure(figsize= (12,12))\n",
        "for i in range(1, 10, 1):\n",
        "    plt.subplot(3,3,i)\n",
        "    img = load_img(folder_path+\"/train/\"+expression+\"/\"+\n",
        "                  os.listdir(folder_path + \"/train/\" + expression)[i], target_size=(picture_size, picture_size))\n",
        "    plt.imshow(img)   \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa38689",
      "metadata": {
        "id": "daa38689"
      },
      "outputs": [],
      "source": [
        "# importing the training and testing data \"FER 2013\"\n",
        "TRAIN_DIR = r\"C:\\Users\\AMARTY JHA\\3D Objects\\data\\train\"\n",
        "TEST_DIR = r\"C:\\Users\\AMARTY JHA\\3D Objects\\data\\test\"\n",
        "#batch_size is number of training examples utilized in one iterartion so here we are defining it is 128\n",
        "BATCH_SIZE=128\n",
        "# the RGB image has pixel range from 0-255 which is very high for our code so we are rescaling it to 0-1 by dividing it with 255 \n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dcab8ea",
      "metadata": {
        "id": "1dcab8ea"
      },
      "outputs": [],
      "source": [
        "#defining the output class variables\n",
        "class_names = ['anger','disgusted','fearful','happy','neutral','sad','surprised']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b124150",
      "metadata": {
        "id": "1b124150"
      },
      "outputs": [],
      "source": [
        "#data augmentation step\n",
        "train_set = train_datagen.flow_from_directory(TRAIN_DIR,\n",
        "                                                 target_size = (48, 48),\n",
        "                                                 batch_size = 64,\n",
        "                                                 class_mode = 'categorical',  #\"categorical\" will be 2D one-hot encoded labels\n",
        "                                                 color_mode= \"grayscale\",\n",
        "                                                 )\n",
        "\n",
        "test_set = val_datagen.flow_from_directory(TEST_DIR,\n",
        "                                            target_size = (48, 48),\n",
        "                                            batch_size = 64,\n",
        "                                            class_mode = 'categorical',\n",
        "                                           color_mode= \"grayscale\",\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be26172",
      "metadata": {
        "id": "6be26172"
      },
      "outputs": [],
      "source": [
        "#this is our customized cnn architecture \n",
        "emotion_model=Sequential()\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(2,2))\n",
        "emotion_model.add(Dropout(.25))\n",
        "\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(2,2))\n",
        "\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(2,2))\n",
        "emotion_model.add(Dropout(.25))\n",
        "\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))#using softmax to get relative probabilities of the seven emotions possible"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is vgg16 architetcture which is a pre-trained cnn model\n",
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1,1),input_shape=(48,48,1)))\n",
        "model.add(Convolution2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512,kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))"
      ],
      "metadata": {
        "id": "CHyBlMgjVDQh"
      },
      "id": "CHyBlMgjVDQh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec63a183",
      "metadata": {
        "id": "ec63a183"
      },
      "outputs": [],
      "source": [
        "#compiling our model with loss , optimizer and metrics\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
        "\n",
        "#to get flow of model, uncomment below line\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0851394d",
      "metadata": {
        "scrolled": false,
        "id": "0851394d"
      },
      "outputs": [],
      "source": [
        "#training model\n",
        "history = model.fit_generator(\n",
        "train_set,\n",
        "steps_per_epoch=28709//64,#448\n",
        "epochs=25,\n",
        "validation_data=test_set,\n",
        "validation_steps=7178//64)\n",
        "#this step can be skipped by directly downloading the \"research50.h5\" or \"model.h5\" file which has our saved model and directly running the next cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5270dd5",
      "metadata": {
        "scrolled": true,
        "id": "b5270dd5"
      },
      "outputs": [],
      "source": [
        "#saving weights of trained model\n",
        "model.save('research50.h5')\n",
        "#uncomment below if you want the vgg16 model \n",
        "#model.save('model.h5') \n",
        "print ('done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rather than training the entire model which takes time , uncomment the line below to directly use the saved pre-trained model\n",
        "#model = load_model(r\"C:\\Users\\itsdi\\research50.h5\")\n",
        "#uncomment below if you want vgg16 model\n",
        "#model=load_model(r\"C:\\Users\\itsdi\\model.h5\")\n",
        "#in the line above in the load_model copy the path of file which has the saved model"
      ],
      "metadata": {
        "id": "MAmvfOmn9iKc"
      },
      "id": "MAmvfOmn9iKc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating the accuracy on the test data\n",
        "model.evaluate(test_set)"
      ],
      "metadata": {
        "id": "IDlbKR5U_DyM"
      },
      "id": "IDlbKR5U_DyM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "last (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}